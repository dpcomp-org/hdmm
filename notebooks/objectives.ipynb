{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "import workload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 4096*2\n",
    "WtW = workload.AllRange(n).WtW\n",
    "\n",
    "def loss(B):\n",
    "    p, n = B.shape\n",
    "    A = np.vstack([np.eye(n), B])\n",
    "    A /= A.sum(axis=0)\n",
    "    AtA1 = np.linalg.pinv(A.T.dot(A))\n",
    "    return np.trace(AtA1.dot(WtW))\n",
    "\n",
    "def loss2(B):\n",
    "    p, n = B.shape\n",
    "    A = np.vstack([np.eye(n), B])\n",
    "    A /= A.sum(axis=0)\n",
    "    AtA1 = np.linalg.inv(A.T.dot(A))\n",
    "    return np.trace(AtA1.dot(WtW))\n",
    "\n",
    "def loss3(B):\n",
    "    p, n = B.shape\n",
    "    scale = 1.0 + B.sum(axis=0)\n",
    "    C = WtW * scale * scale[:,None]\n",
    "    R = np.linalg.inv(np.eye(p) + B.dot(B.T))\n",
    "    Z = B.T.dot(R.dot(B).dot(C))  \n",
    "    return np.trace(C) - np.trace(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.84013172436e+15\n",
      "CPU times: user 33min 57s, sys: 8min 42s, total: 42min 40s\n",
      "Wall time: 6min 12s\n",
      "2.84013172436e+15\n",
      "CPU times: user 3min 31s, sys: 8.06 s, total: 3min 39s\n",
      "Wall time: 30.5 s\n",
      "2.84013172436e+15\n",
      "CPU times: user 9.5 s, sys: 1.11 s, total: 10.6 s\n",
      "Wall time: 1.45 s\n"
     ]
    }
   ],
   "source": [
    "B = np.random.rand(n//16, n)\n",
    "% time print loss(B)\n",
    "% time print loss2(B)\n",
    "% time print loss3(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  37.30844449  137.27831284  139.14281172    3.87000565   39.83951192\n",
      "   59.80511987   16.1916421    53.43979421   -9.55225162   24.46103322\n",
      "   29.30566629   38.94559205   50.22386445   58.48949266   87.08360619\n",
      "   88.59979094]\n",
      "[  59.97127711  132.92201275  134.34116411  -16.59664689   45.37346542\n",
      "   62.43183266   20.14870952   51.00675143  -11.44267155   28.08847923\n",
      "   38.82191048   37.3492665    61.42166993   81.93514808   82.45440844\n",
      "   80.34265457]\n"
     ]
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import lsqr, aslinearoperator\n",
    "\n",
    "def lstsq(A,y):\n",
    "    return lsqr(A, y)[0]\n",
    "\n",
    "def loss(B):\n",
    "    p, n = B.shape\n",
    "    A = np.vstack([np.eye(n), B])\n",
    "    A = A / np.sum(A, axis=0)\n",
    "    AtA1 = np.linalg.inv(np.dot(A.T, A))\n",
    "    return np.trace(np.dot(AtA1, WtW))\n",
    "\n",
    "def loss_and_grad(P, WtW, y):\n",
    "    \"\"\" \n",
    "    P: a un-normalized strategy matrix (may be represented as a LinearOperator)\n",
    "    WtW: a workload matrix (may be represented as a LinearOperator)\n",
    "    y: a noise vector\n",
    "\n",
    "    return the objective and gradient in outer product form \n",
    "    \"\"\"\n",
    "    p, n = P.shape\n",
    "    P = aslinearoperator(P)\n",
    "\n",
    "    scale = P.H.dot(np.ones(p))\n",
    "    D = aslinearoperator(sparse.diags(1.0/scale))\n",
    "\n",
    "    A = P * D\n",
    "    At = A.H\n",
    "\n",
    "    z = lstsq(A, y)\n",
    "    dz = 2 * WtW.dot(z)\n",
    "    ans = z.dot(dz) / 2.0\n",
    "\n",
    "    # term1 = -outer(z, a)\n",
    "    a = lstsq(At, dz)\n",
    "    #term2 = outer(b, c)\n",
    "    b = lstsq(A, a)\n",
    "    c = y - lstsq(At, At.dot(y))\n",
    "    # term3 = outer(d, e)\n",
    "    d = dz - lstsq(A, A.dot(dz))\n",
    "    e = lstsq(At, z)\n",
    "\n",
    "    U = np.vstack([-a,c,e])\n",
    "    V = np.vstack([z,b,d])\n",
    "\n",
    "    u0 = -np.ones(p)\n",
    "    v0 = np.sum(V * P.H.dot(U.T).T, axis=0) / scale**2\n",
    "\n",
    "    return ans, (np.vstack([u0, U]), np.vstack([v0, V/scale]))\n",
    "\n",
    "def grad2(B, WtW):\n",
    "    p, n = B.shape\n",
    "    I = np.eye(n)\n",
    "    A = np.vstack([np.eye(n), B])\n",
    "    ans = np.zeros_like(B)\n",
    "    rep = 1000\n",
    "    for i in range(rep):\n",
    "        y = np.random.laplace(loc=0, scale=1.0/np.sqrt(2), size=p+n)\n",
    "        #y = np.zeros(p+n)\n",
    "        #y[np.random.randint(p+n)] = 1.0\n",
    "        obj, (U,V) = loss_and_grad(A, WtW, y)\n",
    "        ans += U.T[n:].dot(V) / rep\n",
    "    return ans\n",
    "\n",
    "n = 16\n",
    "WtW = workload.AllRange(n).WtW\n",
    "\n",
    "B = np.random.rand(n//16, n)\n",
    "print grad(loss)(B)[0]\n",
    "print grad2(B, WtW)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
