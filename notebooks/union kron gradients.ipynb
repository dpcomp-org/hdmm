{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hdmm import workload\n",
    "\n",
    "def err(A, W):\n",
    "    AtA1 = np.linalg.pinv(A.T.dot(A))\n",
    "    WtW = W.T.dot(W)\n",
    "    return np.sum(WtW * AtA1)\n",
    "\n",
    "def obj(As, W):\n",
    "    V = np.zeros((W.shape[0], len(As)))\n",
    "    Bs = [np.linalg.pinv(A) for A in As]\n",
    "    Xs = [W.dot(B) for B in Bs]\n",
    "    V = np.vstack([np.sum(X**2, axis=1) for X in Xs])\n",
    "    s = np.sum(1.0/V, axis=0)\n",
    "    f = np.sum(1.0 / s)\n",
    "    \n",
    "    dV = 1 / (V**2 * s**2)\n",
    "    dXs = [2*X*dv[:,None] for X, dv in zip(Xs, dV)]\n",
    "    dBs = [W.T.dot(dX) for dX in dXs]\n",
    "    dAs = []\n",
    "    for A, B, dB in zip(As, Bs, dBs):\n",
    "        m, n = A.shape\n",
    "        dA = -B.dot(dB.T).dot(B)\n",
    "        dA += B.dot(B.T).dot(dB).dot(np.eye(m) - A.dot(B))\n",
    "        dA += (np.eye(n) - B.dot(A)).dot(dB).dot(B.T).dot(B)\n",
    "        dAs.append(dA.T)\n",
    "    \n",
    "    return f, dAs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-11.01274238 -20.86668479 -17.04529003 -13.00929539 -10.60649447\n",
      " -32.64858989 -23.29262734  -9.86175454 -38.40060603 -14.22138308\n",
      " -35.52036922 -33.53803085 -29.81053493 -19.46231608 -15.96811841\n",
      " -17.80842562]\n",
      "[-11.01259884 -20.86640997 -17.0450691  -13.0091495  -10.60638053\n",
      " -32.64815327 -23.29232371  -9.86164854 -38.40008985 -14.2212227\n",
      " -35.51989183 -33.53758048 -29.81013569 -19.46206008 -15.96790725\n",
      " -17.80820211]\n"
     ]
    }
   ],
   "source": [
    "W = workload.AllRange(16)\n",
    "A = np.vstack([np.eye(16), np.random.rand(16)])\n",
    "I = np.eye(16)\n",
    "f, dA = obj([A, I], W)\n",
    "\n",
    "approx = np.zeros(16)\n",
    "for i in range(16):\n",
    "    A[i,i] += 1e-5\n",
    "    f1, _ = obj([A,I], W)\n",
    "    approx[i] = (f1 - f) / 1e-5\n",
    "    A[i,i] -= 1e-5\n",
    "print(np.diag(dA[0]))\n",
    "print(approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.08239456914286\n",
      "(9, 8) (6, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryan/virtualenvs/pgm/lib/python3.6/site-packages/autograd/numpy/numpy_vjps.py:444: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return lambda g: g[idxs]\n"
     ]
    }
   ],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "from autograd.extend import defvjp\n",
    "from functools import reduce\n",
    "\n",
    "#def pinv_vjp(g, ans, vs, gvs, A):\n",
    "#    A1 = np.linalg.pinv(A)\n",
    "#    In = np.eye(A.shape[1])\n",
    "#    Im = np.eye(A.shape[0])\n",
    "#    term1 = -np.dot(A1, np.dot(g.T, A1))\n",
    "#    term2 = np.dot(np.dot(A1, A1.T), np.dot(g, Im - np.dot(A, A1)))\n",
    "#    term3 = np.dot(In - np.dot(A1, A), np.dot(g, np.dot(A1.T, A1)))\n",
    "#    return (term1 + term2 + term3).T\n",
    "\n",
    "#np.linalg.pinv.defvjp(pinv_vjp)\n",
    "\n",
    "def pinv_vjp(ans, A):\n",
    "    A1 = np.linalg.pinv(A)\n",
    "    In = np.eye(A.shape[1])\n",
    "    Im = np.eye(A.shape[0])\n",
    "    def foo(g):\n",
    "        term1 = -np.dot(A1, np.dot(g.T, A1))\n",
    "        term2 = np.dot(np.dot(A1, A1.T), np.dot(g, Im - np.dot(A, A1)))\n",
    "        term3 = np.dot(In - np.dot(A1, A), np.dot(g, np.dot(A1.T, A1)))\n",
    "        return (term1 + term2 + term3).T\n",
    "    return foo\n",
    "\n",
    "defvjp(np.linalg.pinv, pinv_vjp)\n",
    "\n",
    "def kron_obj(As, Ws):\n",
    "    # As is a l x d table\n",
    "    # Ws is a k x d table\n",
    "    L = len(As)\n",
    "    K = len(Ws)\n",
    "    D = len(As[0])\n",
    "    \n",
    "    #deltas = sum([reduce(np.kron, [np.sum(A, axis=0)[:,None] for A in kron]) for kron in As])\n",
    "    #delta = np.max(deltas)**2\n",
    "    #delta = np.sum(eps)**2\n",
    "    delta = 1.0\n",
    "    \n",
    "    #print 'delta', np.max(deltas) / np.min(deltas)\n",
    "    \n",
    "    # Todo: global normalization rather than local\n",
    "    Bs = [[np.linalg.pinv(A/np.sum(A, axis=0)) for A in kron] for kron in As]\n",
    "    V = [[None for _ in range(K)] for _ in range(L)]\n",
    "    for l in range(L):\n",
    "        for k in range(K):\n",
    "            v = [None for _ in range(D)]\n",
    "            for d in range(D):\n",
    "                A = As[l][d] / np.sum(As[l][d], axis=0)\n",
    "                X = np.dot(Ws[k][d], Bs[l][d])\n",
    "                # check to make sure strategy supports workload\n",
    "                v[d] = np.sum(X**2, axis=1)[:,None]\n",
    "                if not np.allclose(np.dot(X, A), Ws[k][d]):\n",
    "                    print('checkpt')\n",
    "            V[l][k] = reduce(np.kron, v).flatten()\n",
    "            \n",
    "    V2 = np.array([np.concatenate(vs) for vs in V]) / eps[:,None]**2\n",
    "    \n",
    "    s = np.sum(1.0/V2, axis=0)\n",
    "    f = np.sum(1.0 / s)\n",
    "    return delta*f\n",
    "                \n",
    "I = np.eye(8)\n",
    "A1 = np.vstack([np.eye(8),np.random.rand(8)])\n",
    "A2 = np.vstack([np.eye(5),np.random.rand(5)])\n",
    "As = [[A1, A2]]\n",
    "W1 = np.random.rand(8,8)\n",
    "W2 = np.random.rand(4,5)\n",
    "Ws = [[W1, W2]]\n",
    "eps = np.ones(2)\n",
    "\n",
    "print(kron_obj(As, Ws))\n",
    "dA = grad(kron_obj)(As, Ws)\n",
    "\n",
    "print(dA[0][0].shape, dA[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'experiments.census_workloads'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d823bc762019>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhdmm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mworkload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mexperiments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcensus_workloads\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCensusSF1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mminimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'experiments.census_workloads'"
     ]
    }
   ],
   "source": [
    "from scipy import optimize\n",
    "from hdmm import workload\n",
    "from experiments.census_workloads import CensusSF1\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "sf1 = CensusSF1()\n",
    "\n",
    "Ws = [[S.W for S in K.workloads] for K in sf1.workloads]\n",
    "ps = [1,1,6,1,10]\n",
    "As = [[np.vstack([np.eye(n), np.random.rand(p,n)]) for p, n in zip(ps, sf1.domain)] for _ in range(2)]\n",
    "D = len(As[0])\n",
    "L = len(As)\n",
    "\n",
    "def vect_to_mats(params):\n",
    "    idx = 0\n",
    "    ans = []\n",
    "    for _ in range(2):\n",
    "        Ai = []\n",
    "        for n, p in zip(sf1.domain, ps):\n",
    "            stop = idx+n*(n+p)\n",
    "            Ai.append(params[idx:stop].reshape(n+p, n))\n",
    "            idx = stop\n",
    "        ans.append(Ai)\n",
    "    return ans\n",
    "\n",
    "def mats_to_vect(As):\n",
    "    vects = []\n",
    "    for i in range(2):\n",
    "        vects.append(np.concatenate([A.flatten() for A in As[i]]))\n",
    "    return np.concatenate(vects)\n",
    "\n",
    "gradient1 = grad(kron_obj, argnum=0)\n",
    "#gradient2 = grad(kron_obj, argnum=1)\n",
    "id_err = kron_obj([[np.eye(n) for n in sf1.domain]], Ws)\n",
    "\n",
    "def loss_and_grad(params):\n",
    "    #eps = params[:2]\n",
    "    As = vect_to_mats(params)\n",
    "    #eps = params[:2]\n",
    "    ans = kron_obj(As, Ws)\n",
    "    dAs = gradient1(As, Ws)\n",
    "    #deps = gradient2(As, eps, Ws)\n",
    "    dparams = mats_to_vect(dAs)\n",
    "    print(id_err / ans)\n",
    "    #print ans, params.sum(), np.sum([[np.sum(A) for A in Ai] for Ai in As])\n",
    "    return ans, dparams\n",
    "\n",
    "#print kron_obj(As, Ws)\n",
    "#print grad(kron_obj)(As, Ws)\n",
    "\n",
    "#eps = np.ones(2)\n",
    "params = mats_to_vect(As)\n",
    "bounds = [(0, None)] * params.size\n",
    "res = optimize.minimize(loss_and_grad, x0=params, method='L-BFGS-B', jac=True, bounds=bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 64, 17, 115) 33\n",
      "0.079835069431\n",
      "[[ 0.01244673  0.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.98755327  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "As = vect_to_mats(res.x)\n",
    "print sf1.domain, len(Ws)\n",
    "print kron_obj(As, Ws) / id_err\n",
    "As = vect_to_mats(res.x)\n",
    "def normalize(A):\n",
    "    return A / A.sum(axis=0)\n",
    "print normalize(As[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryan/virtualenvs/PyDpcomp/lib/python2.7/site-packages/ipykernel_launcher.py:42: RuntimeWarning: divide by zero encountered in divide\n"
     ]
    }
   ],
   "source": [
    "Ws = [[S.W for S in K.workloads] for K in sf1.workloads]\n",
    "As = vect_to_mats(res.x)\n",
    "_, V = kron_obj(As, Ws)\n",
    "#dAs = gradient(As, Ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  4.65193887e-04,   2.31354605e-05,   2.63760322e-05, ...,\n",
       "          6.99569653e-06,   6.55013243e-06,   8.45687156e-05]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
