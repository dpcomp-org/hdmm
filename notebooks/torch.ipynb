{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from hdmm.templates import TemplateStrategy\n",
    "from hdmm import workload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.tril(torch.ones(5,5, dtype=torch.uint8), diagonal=-1)\n",
    "B = torch.zeros(5,5)\n",
    "z = torch.rand(10)\n",
    "B[mask] = z\n",
    "#print(B)\n",
    "B = B + torch.t(B)\n",
    "#torch.diag(torch.tensor(0.5), diagonal=0, out=B)\n",
    "torch.diag(B).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "class McKennaConvex(TemplateStrategy):\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "        self._mask = torch.tril(torch.ones(n,n, dtype=torch.uint8), diagonal=-1)\n",
    "        self._params = torch.zeros(n*(n-1)//2)\n",
    "        self.X = torch.zeros(n,n)\n",
    "\n",
    "    def _set_workload(self, W):\n",
    "        self.V = torch.tensor(W.gram().dense_matrix().astype(np.float32))\n",
    "        self.W = W\n",
    "\n",
    "    def _loss(self):\n",
    "        V = self.V\n",
    "        X = 0.5*torch.eye(self.n, out=self.X)\n",
    "        \n",
    "        X[self._mask] = self._params\n",
    "        X = X + torch.t(X) # warning: don't do this in place\n",
    "\n",
    "        try:\n",
    "            zz = torch.cholesky(X)\n",
    "            #iX = torch.cholesky_inverse(zz)\n",
    "            iX = torch.inverse(X)\n",
    "        except:\n",
    "            return torch.tensor(np.inf)\n",
    "      \n",
    "        return torch.sum(iX * V) \n",
    "\n",
    "    def optimize(self, W, iters=5000):\n",
    "        self._set_workload(W)\n",
    "\n",
    "        eig, P = torch.symeig(self.V, eigenvectors=True)\n",
    "        eig[eig < 1e-10] = 0.0\n",
    "        X = P @ torch.diag(torch.sqrt(eig)) @ torch.t(P)\n",
    "        X /= torch.diag(X).max()\n",
    "        \n",
    "        self._params = X[self._mask].requires_grad_(True)\n",
    "        \n",
    "        # have to implement the optimization loop manually :(\n",
    "        \n",
    "        beta = 1.0\n",
    "        for it in range(500):\n",
    "            self._params.detach_().requires_grad_(True)\n",
    "            curr_loss = self._loss()\n",
    "            curr_loss.backward()\n",
    "            params = self._params\n",
    "            for i in range(0, 25):\n",
    "                self._params = params - beta * params.grad.data\n",
    "                loss = self._loss()\n",
    "                if loss < curr_loss:\n",
    "                    break\n",
    "                beta *= 0.5\n",
    "            if it % 100 == 0:\n",
    "                print(beta,torch.sqrt(loss/self.W.shape[0]))\n",
    "            \n",
    "            #print(loss)\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015625 tensor(3.0193, grad_fn=<SqrtBackward>)\n",
      "0.0009765625 tensor(2.8757, grad_fn=<SqrtBackward>)\n",
      "0.0009765625 tensor(2.8355, grad_fn=<SqrtBackward>)\n",
      "0.0009765625 tensor(2.8132, grad_fn=<SqrtBackward>)\n",
      "0.0009765625 tensor(2.7986, grad_fn=<SqrtBackward>)\n"
     ]
    }
   ],
   "source": [
    "n = 512\n",
    "W = workload.Prefix(n)\n",
    "#W = workload.AllRange(n)\n",
    "temp = McKennaConvex(n)\n",
    "temp.optimize(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0682157488120567e-10\n",
      "6390.995693388852\n"
     ]
    }
   ],
   "source": [
    "R = workload.Prefix(64)\n",
    "I = workload.Identity(64)\n",
    "T = workload.Total(64)\n",
    "\n",
    "W = workload.VStack([workload.Kronecker([R,T]), workload.Kronecker([T,R])])\n",
    "A = workload.Kronecker([I,T])\n",
    "\n",
    "WtW = W.gram()\n",
    "A = workload.Marginals((64,64), np.array([0,0,1,0]))\n",
    "AtA = A.gram()\n",
    "AtA1 = AtA.pinv()\n",
    "\n",
    "z = np.random.rand(WtW.shape[0])\n",
    "for X, Y in zip(WtW.matrices, (WtW @ AtA1 @ AtA).matrices):\n",
    "    err = np.linalg.norm(X.dot(z) - Y.dot(z))\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3477.499999999999"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hdmm import error\n",
    "error.expected_error(W, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[64., 64., 64., ...,  1.,  1.,  1.],\n",
       "       [64., 64., 64., ...,  1.,  1.,  1.],\n",
       "       [64., 64., 64., ...,  1.,  1.,  1.],\n",
       "       ...,\n",
       "       [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1., ...,  1.,  1.,  1.]])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WtW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
